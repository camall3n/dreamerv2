action_repeat: 1
actor: {act: elu, dist: auto, layers: 4, min_std: 0.1, norm: none, units: 400}
actor_ent: 0.001
actor_grad: auto
actor_grad_mix: 0.1
actor_opt: {clip: 100, eps: 1e-05, lr: 4e-05, opt: adam, wd: 1e-06}
append_seed: true
atari_grayscale: false
clip_rewards: tanh
critic: {act: elu, dist: mse, layers: 4, norm: none, units: 400}
critic_opt: {clip: 100, eps: 1e-05, lr: 0.0001, opt: adam, wd: 1e-06}
dataset: {batch: 30, length: 25}
decoder:
  act: elu
  cnn_depth: 48
  cnn_kernels: [5, 5, 6, 6]
  cnn_keys: image
  mlp_keys: $^
  mlp_layers: [400, 400, 400, 400]
  norm: none
disag_action_cond: true
disag_log: false
disag_models: 10
disag_offset: 1
disag_target: stoch
discount: 0.99
discount_head: {act: elu, dist: binary, layers: 4, norm: none, units: 600}
discount_lambda: 0.95
dmc_camera: -1
encoder:
  act: elu
  cnn_depth: 48
  cnn_kernels: [4, 4, 4, 4]
  cnn_keys: image
  mlp_keys: $^
  mlp_layers: [400, 400, 400, 400]
  norm: none
envs: 1
envs_parallel: none
eval_eps: 1
eval_every: 50000
eval_noise: 0.0
eval_state_mean: false
expl_behavior: greedy
expl_extr_scale: 0.0
expl_head: {act: elu, dist: mse, layers: 4, norm: none, units: 400}
expl_intr_scale: 1.0
expl_model_loss: kl
expl_noise: 0.0
expl_opt: {clip: 100, eps: 1e-05, lr: 0.0003, opt: adam, wd: 1e-06}
expl_reward_norm: {eps: 1e-08, momentum: 1.0, scale: 1.0}
expl_until: 0
grad_heads: [decoder, reward, discount]
imag_horizon: 15
jit: true
kl: {balance: 0.8, forward: false, free: 0.0, free_avg: true}
log_every: 10000
log_keys_max: ^$
log_keys_mean: ^$
log_keys_sum: reward
log_keys_video: [image]
logdir: ../logs/taxi_1mil_binaryhead_original_seed_01
loss_scales: {discount: 5.0, kl: 0.1, proprio: 1.0, reward: 2.0}
model_opt: {clip: 100, eps: 1e-05, lr: 0.0002, opt: adam, wd: 1e-06}
precision: 32
pred_discount: true
prefill: 10000
pretrain: 1
render_size: [64, 64]
replay: {capacity: 2000, maxlen: 50, minlen: 1, ongoing: false, prioritize_ends: true}
reward_head: {act: elu, dist: binary, layers: 4, norm: none, units: 600}
reward_norm: {eps: 1e-08, momentum: 1.0, scale: 1.0}
rssm: {act: elu, deter: 600, discrete: 32, ensemble: 1, hidden: 600, min_std: 0.1,
  norm: none, std_act: sigmoid2, stoch: 32}
save_step: false
seed: 1
slow_baseline: true
slow_target: true
slow_target_fraction: 1
slow_target_update: 100
steps: 1000000
task: taxi_env
time_limit: 50
train_every: 30
train_steps: 1
